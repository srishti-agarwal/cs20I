{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 8259k  100 8259k    0     0  1749k      0  0:00:04  0:00:04 --:--:-- 1801k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  235M  100  235M    0     0  1156k      0  0:03:28  0:03:28 --:--:-- 1509k    0     0  1180k      0  0:03:24  0:02:19  0:01:05  940k\n"
     ]
    }
   ],
   "source": [
    "!curl -o notMNIST_small.tar.gz http://yaroslavvb.com/upload/notMNIST/notMNIST_small.tar.gz\n",
    "!curl -o notMNIST_large.tar.gz http://yaroslavvb.com/upload/notMNIST/notMNIST_large.tar.gz\n",
    "!tar xzf notMNIST_small.tar.gz\n",
    "!tar xzf notMNIST_large.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "nmnist = read_mnist('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:(55000, 784), Y_train:(55000, 10), X_test: (5000, 784), Y_test: (5000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels, test_images, test_labels = nmnist[0][0], nmnist[0][1], nmnist[1][0], nmnist[1][1]\n",
    "print(\"X_train:{}, Y_train:{}, X_test: {}, Y_test: {}\".format(train_images.shape,train_labels.shape,test_images.shape,\\\n",
    "                                                              test_labels.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(train_images[5].reshape([28,28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None,784])\n",
    "Y= tf.placeholder(tf.float32,[None,10])\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(shape):\n",
    "    weight = tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(weight)\n",
    "\n",
    "def get_bias(shape):\n",
    "    bias = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(bias)\n",
    "\n",
    "def conv2X2(x,w):\n",
    "    return tf.nn.conv2d(x,w,strides=[1,1,1,1],padding=\"SAME\")\n",
    "\n",
    "def max2X2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = train_images.shape[0]\n",
    "batch_size = 100\n",
    "n_batches = int(n_samples/batch_size)\n",
    "\n",
    "W_conv1 = get_weights([5,5,1,32])\n",
    "b_conv1 = get_bias([32])\n",
    "h_conv1 = tf.nn.relu(conv2X2(tf.reshape(X,[-1,28,28,1]),W_conv1) + b_conv1)\n",
    "h_pool1 = max2X2(h_conv1)\n",
    "\n",
    "W_conv2 = get_weights([5,5,32,64])\n",
    "b_conv2 = get_bias([64])\n",
    "h_conv2 = tf.nn.relu(conv2X2(h_pool1,W_conv2) + b_conv2)\n",
    "h_pool2 = max2X2(h_conv2)\n",
    "\n",
    "W_dense1 = get_weights([7*7*64,1024])\n",
    "b_dense1 = get_bias([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])\n",
    "h_dense1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_dense1) + b_dense1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_drop = tf.nn.dropout(h_dense1,keep_prob)\n",
    "\n",
    "W_soft1 = get_weights([1024,10])\n",
    "b_soft1 = get_bias([10])\n",
    "y_pred = tf.matmul(h_dense1,W_soft1) + b_soft1\n",
    "\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=y_pred,labels=Y)\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(entropy)\n",
    "correct_pred = tf.equal(tf.arg_max(y_pred,1), tf.arg_max(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_in_epoch = 0\n",
    "epochs_completed = 0\n",
    "def get_next_batch(batch_size):\n",
    "    \n",
    "    global index_in_epoch\n",
    "    global epochs_completed\n",
    "    global train_images\n",
    "    global train_labels\n",
    "    \n",
    "    start = index_in_epoch\n",
    "    index_in_epoch += batch_size\n",
    "\n",
    "    # when all trainig data have been already used, it is reorder randomly    \n",
    "    if index_in_epoch > n_samples:\n",
    "        # finished epoch\n",
    "        epochs_completed += 1\n",
    "        # shuffle the data\n",
    "        perm = np.arange(n_samples)\n",
    "        np.random.shuffle(perm)\n",
    "        train_images = train_images[perm]\n",
    "        train_labels = train_labels[perm]\n",
    "        # start next epoch\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size\n",
    "        assert batch_size <= n_samples\n",
    "    end = index_in_epoch\n",
    "    return train_images[start:end], train_labels[start:end]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0,accuracy:0.8899999856948853\n",
      "step:100,accuracy:0.8500000238418579\n",
      "step:200,accuracy:0.8999999761581421\n",
      "step:300,accuracy:0.9200000166893005\n",
      "step:400,accuracy:0.9300000071525574\n",
      "step:500,accuracy:0.9200000166893005\n",
      "step:600,accuracy:0.9700000286102295\n",
      "step:700,accuracy:0.9300000071525574\n",
      "step:800,accuracy:0.8999999761581421\n",
      "step:900,accuracy:0.8899999856948853\n",
      "step:1000,accuracy:0.8600000143051147\n",
      "step:1100,accuracy:0.949999988079071\n",
      "step:1200,accuracy:0.9300000071525574\n",
      "step:1300,accuracy:0.9700000286102295\n",
      "step:1400,accuracy:0.8999999761581421\n",
      "step:1500,accuracy:0.949999988079071\n",
      "step:1600,accuracy:0.9200000166893005\n",
      "step:1700,accuracy:0.9200000166893005\n",
      "step:1800,accuracy:0.949999988079071\n",
      "step:1900,accuracy:0.8999999761581421\n",
      "step:2000,accuracy:0.9399999976158142\n",
      "step:2100,accuracy:0.8899999856948853\n",
      "step:2200,accuracy:0.9599999785423279\n",
      "step:2300,accuracy:0.9200000166893005\n",
      "step:2400,accuracy:0.9399999976158142\n",
      "step:2500,accuracy:0.9200000166893005\n",
      "step:2600,accuracy:0.9300000071525574\n",
      "step:2700,accuracy:0.9399999976158142\n",
      "step:2800,accuracy:0.9700000286102295\n",
      "step:2900,accuracy:0.9399999976158142\n",
      "step:3000,accuracy:0.9700000286102295\n",
      "step:3100,accuracy:0.949999988079071\n",
      "step:3200,accuracy:0.9399999976158142\n",
      "step:3300,accuracy:0.9700000286102295\n",
      "step:3400,accuracy:0.9399999976158142\n",
      "step:3500,accuracy:0.9900000095367432\n",
      "step:3600,accuracy:0.9300000071525574\n",
      "step:3700,accuracy:0.9399999976158142\n",
      "step:3800,accuracy:0.9200000166893005\n",
      "step:3900,accuracy:0.9300000071525574\n",
      "step:4000,accuracy:0.949999988079071\n",
      "step:4100,accuracy:0.9599999785423279\n",
      "step:4200,accuracy:0.949999988079071\n",
      "step:4300,accuracy:0.9800000190734863\n",
      "step:4400,accuracy:0.9900000095367432\n",
      "step:4500,accuracy:0.949999988079071\n",
      "step:4600,accuracy:0.9700000286102295\n",
      "step:4700,accuracy:0.9900000095367432\n",
      "step:4800,accuracy:0.949999988079071\n",
      "step:4900,accuracy:0.9700000286102295\n",
      "step:5000,accuracy:0.949999988079071\n",
      "step:5100,accuracy:0.9700000286102295\n",
      "step:5200,accuracy:0.949999988079071\n",
      "step:5300,accuracy:0.9700000286102295\n",
      "step:5400,accuracy:0.9599999785423279\n",
      "step:5500,accuracy:0.9700000286102295\n",
      "step:5600,accuracy:0.9599999785423279\n",
      "step:5700,accuracy:0.9700000286102295\n",
      "step:5800,accuracy:0.9900000095367432\n",
      "step:5900,accuracy:0.9700000286102295\n",
      "step:6000,accuracy:0.9200000166893005\n",
      "step:6100,accuracy:0.949999988079071\n",
      "step:6200,accuracy:0.9599999785423279\n",
      "step:6300,accuracy:1.0\n",
      "step:6400,accuracy:1.0\n",
      "step:6500,accuracy:0.9700000286102295\n",
      "step:6600,accuracy:0.9800000190734863\n",
      "step:6700,accuracy:1.0\n",
      "step:6800,accuracy:0.9700000286102295\n",
      "step:6900,accuracy:0.9800000190734863\n",
      "step:7000,accuracy:0.9900000095367432\n",
      "step:7100,accuracy:0.9900000095367432\n",
      "step:7200,accuracy:1.0\n",
      "step:7300,accuracy:0.9800000190734863\n",
      "step:7400,accuracy:0.9900000095367432\n",
      "step:7500,accuracy:0.9800000190734863\n",
      "step:7600,accuracy:0.9900000095367432\n",
      "step:7700,accuracy:0.9900000095367432\n",
      "step:7800,accuracy:0.9900000095367432\n",
      "step:7900,accuracy:0.9900000095367432\n",
      "step:8000,accuracy:1.0\n",
      "step:8100,accuracy:0.9800000190734863\n",
      "step:8200,accuracy:1.0\n",
      "step:8300,accuracy:0.9700000286102295\n",
      "step:8400,accuracy:0.949999988079071\n",
      "step:8500,accuracy:0.9900000095367432\n",
      "step:8600,accuracy:0.9900000095367432\n",
      "step:8700,accuracy:0.9900000095367432\n",
      "step:8800,accuracy:1.0\n",
      "step:8900,accuracy:0.9900000095367432\n",
      "step:9000,accuracy:1.0\n",
      "step:9100,accuracy:0.9700000286102295\n",
      "step:9200,accuracy:0.9900000095367432\n",
      "step:9300,accuracy:1.0\n",
      "step:9400,accuracy:1.0\n",
      "step:9500,accuracy:0.9900000095367432\n",
      "step:9600,accuracy:1.0\n",
      "step:9700,accuracy:1.0\n",
      "step:9800,accuracy:1.0\n",
      "step:9900,accuracy:1.0\n",
      "step:10000,accuracy:1.0\n",
      "step:10100,accuracy:1.0\n",
      "step:10200,accuracy:1.0\n",
      "step:10300,accuracy:0.9800000190734863\n",
      "step:10400,accuracy:0.9900000095367432\n",
      "step:10500,accuracy:1.0\n",
      "step:10600,accuracy:0.9599999785423279\n",
      "step:10700,accuracy:0.9900000095367432\n",
      "step:10800,accuracy:0.9900000095367432\n",
      "step:10900,accuracy:1.0\n",
      "step:11000,accuracy:1.0\n",
      "step:11100,accuracy:1.0\n",
      "step:11200,accuracy:1.0\n",
      "step:11300,accuracy:1.0\n",
      "step:11400,accuracy:0.9700000286102295\n",
      "step:11500,accuracy:1.0\n",
      "step:11600,accuracy:0.9900000095367432\n",
      "step:11700,accuracy:1.0\n",
      "step:11800,accuracy:0.9900000095367432\n",
      "step:11900,accuracy:0.9800000190734863\n",
      "step:12000,accuracy:0.9900000095367432\n",
      "step:12100,accuracy:1.0\n",
      "step:12200,accuracy:1.0\n",
      "step:12300,accuracy:1.0\n",
      "step:12400,accuracy:1.0\n",
      "step:12500,accuracy:1.0\n",
      "step:12600,accuracy:1.0\n",
      "step:12700,accuracy:0.9900000095367432\n",
      "step:12800,accuracy:0.9900000095367432\n",
      "step:12900,accuracy:0.9900000095367432\n",
      "step:13000,accuracy:1.0\n",
      "step:13100,accuracy:1.0\n",
      "step:13200,accuracy:0.9900000095367432\n",
      "step:13300,accuracy:0.9800000190734863\n",
      "step:13400,accuracy:1.0\n",
      "step:13500,accuracy:0.9900000095367432\n",
      "step:13600,accuracy:0.9900000095367432\n",
      "step:13700,accuracy:1.0\n",
      "step:13800,accuracy:1.0\n",
      "step:13900,accuracy:0.9900000095367432\n",
      "step:14000,accuracy:0.9900000095367432\n",
      "step:14100,accuracy:1.0\n",
      "step:14200,accuracy:1.0\n",
      "step:14300,accuracy:1.0\n",
      "step:14400,accuracy:1.0\n",
      "step:14500,accuracy:1.0\n",
      "step:14600,accuracy:1.0\n",
      "step:14700,accuracy:0.9800000190734863\n",
      "step:14800,accuracy:1.0\n",
      "step:14900,accuracy:1.0\n",
      "step:15000,accuracy:1.0\n",
      "step:15100,accuracy:1.0\n",
      "step:15200,accuracy:1.0\n",
      "step:15300,accuracy:1.0\n",
      "step:15400,accuracy:1.0\n",
      "step:15500,accuracy:1.0\n",
      "step:15600,accuracy:1.0\n",
      "step:15700,accuracy:1.0\n",
      "step:15800,accuracy:0.9900000095367432\n",
      "step:15900,accuracy:0.9700000286102295\n",
      "step:16000,accuracy:1.0\n",
      "step:16100,accuracy:0.9900000095367432\n",
      "step:16200,accuracy:1.0\n",
      "step:16300,accuracy:0.9800000190734863\n",
      "step:16400,accuracy:1.0\n",
      "step:16500,accuracy:1.0\n",
      "step:16600,accuracy:0.9900000095367432\n",
      "step:16700,accuracy:0.9900000095367432\n",
      "step:16800,accuracy:1.0\n",
      "step:16900,accuracy:1.0\n",
      "step:17000,accuracy:0.9900000095367432\n",
      "step:17100,accuracy:0.9599999785423279\n",
      "step:17200,accuracy:1.0\n",
      "step:17300,accuracy:1.0\n",
      "step:17400,accuracy:1.0\n",
      "step:17500,accuracy:1.0\n",
      "step:17600,accuracy:1.0\n",
      "step:17700,accuracy:1.0\n",
      "step:17800,accuracy:1.0\n",
      "step:17900,accuracy:1.0\n",
      "step:18000,accuracy:1.0\n",
      "step:18100,accuracy:1.0\n",
      "step:18200,accuracy:1.0\n",
      "step:18300,accuracy:1.0\n",
      "step:18400,accuracy:1.0\n",
      "step:18500,accuracy:1.0\n",
      "step:18600,accuracy:1.0\n",
      "step:18700,accuracy:1.0\n",
      "step:18800,accuracy:0.9900000095367432\n",
      "step:18900,accuracy:0.9900000095367432\n",
      "step:19000,accuracy:1.0\n",
      "step:19100,accuracy:1.0\n",
      "step:19200,accuracy:1.0\n",
      "step:19300,accuracy:1.0\n",
      "step:19400,accuracy:1.0\n",
      "step:19500,accuracy:1.0\n",
      "step:19600,accuracy:1.0\n",
      "step:19700,accuracy:1.0\n",
      "step:19800,accuracy:1.0\n",
      "step:19900,accuracy:1.0\n"
     ]
    }
   ],
   "source": [
    "begin,end=0,0\n",
    "for i in range(20000):\n",
    "    batch = get_next_batch(batch_size)\n",
    "    if i%100 ==0:\n",
    "        print(\"step:{},accuracy:{}\".format(i,accuracy.eval(feed_dict={X:batch[0],Y:batch[1],keep_prob:1.0})))\n",
    "    train_step.run(feed_dict={X:batch[0],Y:batch[1],keep_prob:0.5}) \n",
    "test_accuracy = accuracy.eval(feed_dict={X:test_images,Y:test_labels,keep_prob:1.0})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.906000018119812\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = y_pred.eval(feed_dict={X:test_images,Y:test_labels,keep_prob:1.0})\n",
    "predicted_label = []\n",
    "for pe in predictions:\n",
    "    predicted_label.append(np.argmax(pe))\n",
    "actual_label = []\n",
    "for a in test_labels:\n",
    "    actual_label.append(np.argmax(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.91      0.91       507\n",
      "          1       0.85      0.94      0.89       515\n",
      "          2       0.95      0.90      0.92       499\n",
      "          3       0.91      0.90      0.90       518\n",
      "          4       0.93      0.89      0.91       509\n",
      "          5       0.94      0.91      0.92       507\n",
      "          6       0.92      0.93      0.92       466\n",
      "          7       0.90      0.92      0.91       492\n",
      "          8       0.86      0.87      0.87       507\n",
      "          9       0.92      0.89      0.91       480\n",
      "\n",
      "avg / total       0.91      0.91      0.91      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(actual_label,predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
